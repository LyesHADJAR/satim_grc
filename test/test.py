"""
Test the Enhanced GRC System - FINAL FIXED VERSION
"""
import asyncio
import logging
import sys
import os
import json
from datetime import datetime, timezone

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("âœ… .env file loaded")
except ImportError:
    print("âš ï¸ python-dotenv not installed - using system environment variables only")

# Check for google-generativeai
try:
    import google.generativeai as genai
    print("âœ… google-generativeai package loaded successfully")
except ImportError:
    print("âŒ google-generativeai package not installed")
    print("ğŸ’¡ Install with: pip install google-generativeai")
    sys.exit(1)

# Add the parent directory to sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import the fixed enhanced system
from agents.policy_comparison_agent import EnhancedPolicyComparisonAgent
from agents.communication_protocol import AgentCommunicationProtocol
from rag.query_engine import EnhancedRAGQueryEngine

async def test_enhanced_real_llm_analysis():
    """Test the enhanced real LLM analysis system."""
    
    # Set up logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸš€ ENHANCED GRC AUTOMATION - REAL LLM ANALYSIS (FIXED) ğŸš€")
    print("="*70)
    print(f"ğŸ“… Date: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} UTC")
    print(f"ğŸ‘¤ User: LyesHADJAR")
    print("ğŸ¤– Powered by REAL Gemini Flash 2.0 with Enhanced Analysis")
    print("="*70)
    
    # Verify API key first
    api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_AI_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("\nâŒ CRITICAL: Gemini API key not found!")
        return
    
    print(f"\nâœ… Gemini API Key: Configured ({api_key[:10]}...{api_key[-4:]})")
    
    # Set up data paths
    base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_paths = {
        "company_policies": os.path.join(base_path, "preprocessing", "policies", "satim_chunks_cleaned.json"),
        "reference_policies": os.path.join(base_path, "preprocessing", "norms", "international_norms", "pci_dss_chunks.json")
    }
    
    # Verify data files
    print("\nğŸ”§ DATA VERIFICATION:")
    for name, path in data_paths.items():
        if os.path.exists(path):
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… {name}: {len(data)} chunks loaded")
            print(f"   ğŸ“Š Content: {sum(len(chunk.get('text', '')) for chunk in data):,} characters")
            print(f"   ğŸ“„ Sample: {data[0].get('document', 'Unknown')}")
        else:
            print(f"âŒ {name}: FILE NOT FOUND - {path}")
            return
    
    try:
        print(f"\nğŸ”§ INITIALIZING ENHANCED SYSTEMS:")
        
        # Initialize enhanced RAG engine
        rag_engine = EnhancedRAGQueryEngine(
            llm_config={
                "provider": "gemini",
                "model": "gemini-2.0-flash-exp",
                "temperature": 0.2,
                "max_tokens": 4000,
                "api_key": api_key
            },
            data_paths=data_paths
        )
        print("âœ… Enhanced RAG Engine initialized")
        
        # Initialize agent communication protocol
        communication_protocol = AgentCommunicationProtocol()
        print("âœ… Agent Communication Protocol initialized")
        
        # Initialize FIXED enhanced policy comparison agent
        agent = EnhancedPolicyComparisonAgent(
            name="enhanced_policy_analyzer",
            llm_config={
                "provider": "gemini",
                "model": "gemini-2.0-flash-exp",
                "temperature": 0.2,
                "api_key": api_key
            },
            rag_engine=rag_engine,
            communication_protocol=communication_protocol
        )
        print("âœ… Enhanced Policy Comparison Agent (FIXED) initialized")
        
        # Test content retrieval
        print(f"\nğŸ” TESTING ENHANCED CONTENT RETRIEVAL:")
        search_results = await rag_engine.semantic_search("access control authentication requirements", top_k=5)
        print(f"âœ… Found {len(search_results)} relevant sections")
        for i, result in enumerate(search_results[:3], 1):
            print(f"   {i}. {result['section'][:60]}... (Score: {result['similarity_score']:.3f})")
        
        # Run enhanced analysis
        input_data = {
            "company_policy_ids": ["satim", "access control", "incident response"],
            "reference_policy_ids": ["pci-dss"],
            "domains": ["access_control", "incident_response", "data_protection"]
        }
        
        print(f"\nğŸ”„ RUNNING ENHANCED REAL LLM ANALYSIS:")
        print(f"   ğŸ¢ Company Policies: {input_data['company_policy_ids']}")
        print(f"   ğŸ“‹ Reference Standards: {input_data['reference_policy_ids']}")
        print(f"   ğŸ¯ Analysis Domains: {input_data['domains']}")
        print(f"   ğŸ¤– Analysis Mode: Enhanced Real LLM (FIXED)")
        
        # Perform comprehensive analysis
        results = await agent.process(input_data)
        
        print("\n" + "="*70)
        print("ğŸ“Š ENHANCED REAL LLM ANALYSIS RESULTS")
        print("="*70)
        
        domain_scores = []
        total_gaps = 0
        
        for domain, domain_results in results["domain_results"].items():
            print(f"\nğŸ¯ DOMAIN: {domain.upper()}")
            print("â”€" * 60)
            
            coverage = domain_results['coverage']
            gaps = domain_results['gaps']
            score = domain_results['score']
            quantitative_scores = domain_results['quantitative_scores']
            insights = domain_results.get('strategic_insights', {})
            
            domain_scores.append(score.score)
            total_gaps += len(gaps)
            
            # Enhanced Coverage Analysis
            print(f"ğŸ“ˆ COMPREHENSIVE COVERAGE ANALYSIS:")
            print(f"   â€¢ Coverage Percentage: {coverage['coverage_percentage']:.1f}%")
            print(f"   â€¢ Topics Covered: {coverage['topics_covered']}/{coverage['total_reference_topics']}")
            print(f"   â€¢ Coverage Depth: {coverage['coverage_depth']}")
            print(f"   â€¢ Maturity Level: {coverage['maturity_level']}")
            
            # Quantitative Scoring
            print(f"\nğŸ“Š QUANTITATIVE SCORES:")
            print(f"   â€¢ Coverage Score: {quantitative_scores['coverage_score']:.1f}/100")
            print(f"   â€¢ Quality Score: {quantitative_scores['quality_score']:.1f}/100")
            print(f"   â€¢ Alignment Score: {quantitative_scores['alignment_score']:.1f}/100")
            print(f"   â€¢ Implementation Score: {quantitative_scores['implementation_score']:.1f}/100")
            
            # Gap Analysis
            print(f"\nğŸ” DETAILED GAP ANALYSIS ({len(gaps)} gaps identified):")
            for i, gap in enumerate(gaps[:3], 1):
                severity_emoji = {
                    "Critical": "ğŸš¨", "High": "âš ï¸", "Medium": "ğŸ’¡", "Low": "ğŸ“"
                }.get(gap['severity'], "ğŸ“")
                print(f"   {severity_emoji} Gap {i}: {gap['title']}")
                print(f"      ğŸ“Š Severity: {gap['severity']} | Risk Impact: {gap.get('risk_impact', 'Medium')}")
                print(f"      ğŸ’¡ Recommendation: {gap['recommendation'][:100]}...")
            
            # Strategic Insights
            if insights:
                print(f"\nğŸ§  STRATEGIC INSIGHTS:")
                if insights.get('key_strengths'):
                    print(f"   ğŸ’ª Key Strengths:")
                    for strength in insights['key_strengths'][:2]:
                        print(f"      â€¢ {strength}")
                
                if insights.get('improvement_priorities'):
                    print(f"   ğŸ“ˆ Improvement Priorities:")
                    for priority in insights['improvement_priorities'][:2]:
                        print(f"      â€¢ {priority}")
            
            # Domain Score
            score_emoji = "ğŸŸ¢" if score.score >= 75 else "ğŸŸ¡" if score.score >= 55 else "ğŸ”´"
            print(f"\n{score_emoji} ENHANCED COMPLIANCE SCORE: {score.score:.1f}/100")
            print(f"   ğŸ“Š Score Components:")
            for criterion in score.criteria:
                comp_emoji = "ğŸŸ¢" if criterion['score'] >= 75 else "ğŸŸ¡" if criterion['score'] >= 55 else "ğŸ”´"
                print(f"      {comp_emoji} {criterion['name']}: {criterion['score']:.1f} (weight: {criterion['weight']:.0%})")
            
            print("â”€" * 60)
        
        # Overall Assessment
        overall_score = results['overall_score']
        overall_emoji = "ğŸŸ¢" if overall_score.score >= 75 else "ğŸŸ¡" if overall_score.score >= 55 else "ğŸ”´"
        
        print(f"\n{overall_emoji} ENTERPRISE COMPLIANCE ASSESSMENT")
        print("="*60)
        print(f"ğŸ“Š Enterprise Score: {overall_score.score:.1f}/100")
        print(f"ğŸ“ˆ Domain Score Range: {min(domain_scores):.1f} - {max(domain_scores):.1f}")
        print(f"ğŸ” Total Gaps Identified: {total_gaps}")
        
        # Enterprise Assessment Level
        if overall_score.score >= 80:
            assessment_level = "ğŸŸ¢ ADVANCED - Mature compliance framework with strong controls"
        elif overall_score.score >= 65:
            assessment_level = "ğŸŸ¡ DEVELOPING - Good foundation with targeted improvements needed"
        elif overall_score.score >= 50:
            assessment_level = "ğŸŸ¡ EMERGING - Basic framework requiring enhancement"
        else:
            assessment_level = "ğŸ”´ INITIAL - Foundational development required"
        
        print(f"ğŸ¯ Enterprise Assessment: {assessment_level}")
        
        # Strategic Recommendations
        print(f"\nğŸ“‹ STRATEGIC ENTERPRISE RECOMMENDATIONS:")
        for i, rec in enumerate(overall_score.recommendations[:8], 1):
            print(f"   {i}. {rec}")
        
        # Performance Metrics
        print(f"\nâš¡ PERFORMANCE METRICS:")
        print(f"   â€¢ Analysis Quality: Real Gemini Flash 2.0 (Enhanced & Fixed)")
        print(f"   â€¢ Domains Analyzed: {len(results['domain_results'])}")
        print(f"   â€¢ Evidence-Based Analysis: âœ… Yes")
        print(f"   â€¢ Agent Collaboration: âœ… Active")
        
        # Risk Summary
        print(f"\nğŸ¯ EXECUTIVE RISK SUMMARY:")
        critical_gaps = sum(1 for domain_result in results['domain_results'].values() 
                           for gap in domain_result['gaps'] 
                           if gap.get('severity') in ['Critical', 'High'])
        
        print(f"   âš ï¸ High Priority Items: {critical_gaps}")
        print(f"   ğŸ“Š Overall Risk Level: {'Medium' if critical_gaps > 3 else 'Low'}")
        
        print(f"\nâœ¨ Enhanced real LLM analysis complete!")
        print(f"ğŸ‰ SATIM policies analyzed with comprehensive AI intelligence!")
        print(f"ğŸ”¥ Analysis quality: {overall_score.score:.1f}% compliance score achieved!")
        
        # Test agent collaboration
        print(f"\nğŸ¤ TESTING AGENT COLLABORATION:")
        from agents.communication_protocol import AgentRequest, RequestType
        
        test_request = AgentRequest(
            request_id="test_001",
            requesting_agent="test_coordinator",
            target_agent="enhanced_policy_analyzer",
            request_type=RequestType.CONTENT_ANALYSIS,
            data={"domain": "access_control", "content": ["test content"]}
        )
        
        collaboration_response = await communication_protocol.request_analysis(test_request)
        if collaboration_response.success:
            print("   âœ… Agent collaboration working successfully")
            print(f"   ğŸ“Š Response data keys: {list(collaboration_response.data.keys())}")
        else:
            print(f"   âŒ Agent collaboration failed: {collaboration_response.error_message}")
        
    except Exception as e:
        print(f"âŒ Error during enhanced analysis: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸ”§ ENHANCED REAL LLM ANALYSIS SYSTEM (FIXED):")
    print("   âœ… Enhanced policy comparison agent (FIXED)")
    print("   âœ… Real Gemini Flash 2.0 integration")
    print("   âœ… Comprehensive context building")
    print("   âœ… Evidence-based gap identification")
    print("   âœ… Quantitative scoring framework")
    print("   âœ… Strategic enterprise assessment")
    print("")
    
    asyncio.run(test_enhanced_real_llm_analysis())